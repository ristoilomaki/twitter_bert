{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 16:39:29.386549: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-06 16:39:29.386587: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from transformers import TFDistilBertForSequenceClassification, TextClassificationPipeline, DistilBertTokenizerFast\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "### for the import below: pip install datasets ###\n",
    "\n",
    "from datasets import list_metrics, load_metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 16:39:31.375047: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-04-06 16:39:31.375076: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-06 16:39:31.375097: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jupyter-schulma1): /proc/driver/nvidia/version does not exist\n",
      "2022-04-06 16:39:31.375296: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-06 16:39:31.418789: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "All model checkpoint layers were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFDistilBertForSequenceClassification were initialized from the model checkpoint at ./models/..\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFDistilBertForSequenceClassification.from_pretrained('./models/.')\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('./models/tf_tokenizer/.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = TextClassificationPipeline(model = model, tokenizer = tokenizer, return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'LABEL_0', 'score': 0.22559571266174316},\n",
       "  {'label': 'LABEL_1', 'score': 0.7744042873382568}]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"I hate the government restrictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_excel('tweets_labeled.xlsx')\n",
    "tweets = d['full_text'][:600]\n",
    "labels = d['Label (critical: 1/neutral: 0)'][:600]\n",
    "data = pd.DataFrame({'tweets': tweets, 'labels': labels})\n",
    "\n",
    "data_train, data_test = train_test_split(data,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "def predict_label(tweet):\n",
    "    pred = pipe(tweet)\n",
    "    if pred[0][0]['score'] > pred[0][1]['score']: # predicts the label that has higher probability\n",
    "        label = 0\n",
    "    else:\n",
    "        label = 1\n",
    "    return label\n",
    "\n",
    "predicted_labels = []\n",
    "for t in data_test['tweets']:\n",
    "    predicted_labels.append(predict_label(t))\n",
    "\n",
    "print(len(predicted_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accuracy', 'bertscore', 'bleu', 'bleurt', 'cer', 'chrf', 'code_eval', 'comet', 'competition_math', 'coval', 'cuad', 'exact_match', 'f1', 'frugalscore', 'gleu', 'glue', 'google_bleu', 'indic_glue', 'mae', 'mahalanobis', 'matthews_correlation', 'mauve', 'mean_iou', 'meteor', 'mse', 'pearsonr', 'perplexity', 'precision', 'recall', 'rouge', 'sacrebleu', 'sari', 'seqeval', 'spearmanr', 'squad', 'squad_v2', 'super_glue', 'ter', 'wer', 'wiki_split', 'xnli', 'xtreme_s']\n"
     ]
    }
   ],
   "source": [
    "print(list_metrics()) # list of available metrics\n",
    "\n",
    "metric_accuracy = load_metric('accuracy')\n",
    "metric_f1 = load_metric('f1')\n",
    "metric_precision = load_metric('precision')\n",
    "metric_recall = load_metric('recall')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment for info on usage\n",
    "\n",
    "#print(metric_accuracy)\n",
    "#print(metric_f1)\n",
    "#print(metric_precision)\n",
    "#print(metric_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                tweets  labels\n",
      "446  Come on, people.\\nYou can’t be unhappy when th...     1.0\n",
      "404  RT @DrEricDing: Can’t believe @GovRonDeSantis ...     1.0\n",
      "509  Total Covid Death Distribution by County  For ...     0.0\n",
      "455  RT @njoyflyfishing: Total Covid Death Distribu...     0.0\n",
      "201  Students of history should have foreseen Russi...     0.0\n",
      "..                                                 ...     ...\n",
      "5    RT @njoyflyfishing: Total Covid Death Distribu...     0.0\n",
      "224  The truth is in this report, and we have been ...     1.0\n",
      "159  RT @awamkisena: Back to School #Quest for educ...     0.0\n",
      "38   If you've got #Covid symptoms, PCR testing sit...     0.0\n",
      "192  RT @the_hindu: #China is seeing a new surge in...     1.0\n",
      "\n",
      "[120 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "refs = data_test['labels']\n",
    "preds = predicted_labels\n",
    "results = [metric_accuracy.compute(references=refs, predictions=preds),\n",
    "           metric_f1.compute(references=refs, predictions=preds),\n",
    "           metric_precision.compute(references=refs, predictions=preds, average='binary'),\n",
    "           metric_recall.compute(references=refs, predictions=preds, average='binary')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  accuracy        f1    precision    recall\n",
      "----------  --------  -----------  --------\n",
      "  0.858333  0.738462     0.827586  0.666667\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "headers = []\n",
    "values = []\n",
    "for i in results:\n",
    "    for key in i.keys():\n",
    "        headers.append(key)\n",
    "        values.append(i[key])\n",
    "print(tabulate([values], headers=headers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1699b388bd678768f544dd6534e58979417dc4074b6b5ce767e74c5ad0a1cf40"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
