{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sources: https://medium.com/mlearning-ai/sentiment-classification-using-distil-bert-on-custom-dataset-7ecc73b5cb0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_excel('tweets_semi_labeled.xlsx')\n",
    "tweets = d['full_text'][:200]\n",
    "labels = d['Label (critical: 1/neutral: 0)'][:200]\n",
    "data = pd.DataFrame({'tweets': tweets, 'labels': labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data_train, data_test = train_test_split(data,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ktrain\n",
    "from ktrain import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'digitalepidemiologylab/covid-twitter-bert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\risto\\OneDrive\\Asiakirjat\\masters\\SNLP\\project\\venv\\lib\\site-packages\\ktrain\\utils.py:637: UserWarning: class_names implies classification but targets array contains float(s) instead of integers or strings\n",
      "  warnings.warn('class_names implies classification but targets array contains float(s) instead of integers or strings')\n",
      "c:\\Users\\risto\\OneDrive\\Asiakirjat\\masters\\SNLP\\project\\venv\\lib\\site-packages\\ktrain\\utils.py:637: UserWarning: class_names implies classification but targets array contains float(s) instead of integers or strings\n",
      "  warnings.warn('class_names implies classification but targets array contains float(s) instead of integers or strings')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['not_labels', 'labels']\n",
      "     not_labels  labels\n",
      "101         0.0     1.0\n",
      "148         1.0     0.0\n",
      "22          1.0     0.0\n",
      "55          1.0     0.0\n",
      "93          1.0     0.0\n",
      "['not_labels', 'labels']\n",
      "    not_labels  labels\n",
      "78         1.0     0.0\n",
      "15         1.0     0.0\n",
      "90         1.0     0.0\n",
      "30         1.0     0.0\n",
      "6          1.0     0.0\n",
      "downloading pretrained BERT model (uncased_L-12_H-768_A-12.zip)...\n",
      "[██████████████████████████████████████████████████]\n",
      "extracting pretrained BERT model...\n",
      "done.\n",
      "\n",
      "cleanup downloaded zip...\n",
      "done.\n",
      "\n",
      "preprocessing train...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train, test, preprocess = text.texts_from_df(data_train,text_column='tweets',\n",
    "                                                    label_columns='labels',    \n",
    "                                                    preprocess_mode='bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "maxlen is 400\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "model=text.text_classifier('bert',train_data=train,preproc \n",
    "                   =preprocess,verbose=1)\n",
    "# TODO: replace model name with the name of your model\n",
    "# probably 'digitalepidemiologylab/covid-twitter-bert' is good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input-Token, Input-Segment with unsupported characters which will be renamed to input_token, input_segment in the SavedModel.\n",
      "WARNING:absl:<keras_layer_normalization.layer_normalization.LayerNormalization object at 0x000001F061417220> has the same name 'LayerNormalization' as a built-in Keras object. Consider renaming <class 'keras_layer_normalization.layer_normalization.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x000001F06144C2E0> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'keras_multi_head.multi_head_attention.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_layer_normalization.layer_normalization.LayerNormalization object at 0x000001F06140D760> has the same name 'LayerNormalization' as a built-in Keras object. Consider renaming <class 'keras_layer_normalization.layer_normalization.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_layer_normalization.layer_normalization.LayerNormalization object at 0x000001F0630FB4F0> has the same name 'LayerNormalization' as a built-in Keras object. Consider renaming <class 'keras_layer_normalization.layer_normalization.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x000001F06319F790> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'keras_multi_head.multi_head_attention.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_layer_normalization.layer_normalization.LayerNormalization object at 0x000001F061456DC0> has the same name 'LayerNormalization' as a built-in Keras object. Consider renaming <class 'keras_layer_normalization.layer_normalization.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_layer_normalization.layer_normalization.LayerNormalization object at 0x000001F0614299D0> has the same name 'LayerNormalization' as a built-in Keras object. Consider renaming <class 'keras_layer_normalization.layer_normalization.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x000001F06310A820> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'keras_multi_head.multi_head_attention.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_layer_normalization.layer_normalization.LayerNormalization object at 0x000001F0613B5130> has the same name 'LayerNormalization' as a built-in Keras object. Consider renaming <class 'keras_layer_normalization.layer_normalization.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_layer_normalization.layer_normalization.LayerNormalization object at 0x000001F0631B35E0> has the same name 'LayerNormalization' as a built-in Keras object. Consider renaming <class 'keras_layer_normalization.layer_normalization.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x000001F06135D340> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'keras_multi_head.multi_head_attention.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_layer_normalization.layer_normalization.LayerNormalization object at 0x000001F0613B3670> has the same name 'LayerNormalization' as a built-in Keras object. Consider renaming <class 'keras_layer_normalization.layer_normalization.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_layer_normalization.layer_normalization.LayerNormalization object at 0x000001F063266700> has the same name 'LayerNormalization' as a built-in Keras object. Consider renaming <class 'keras_layer_normalization.layer_normalization.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x000001F06326DBE0> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'keras_multi_head.multi_head_attention.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_layer_normalization.layer_normalization.LayerNormalization object at 0x000001F06346BF10> has the same name 'LayerNormalization' as a built-in Keras object. Consider renaming <class 'keras_layer_normalization.layer_normalization.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_layer_normalization.layer_normalization.LayerNormalization object at 0x000001F0634B88E0> has the same name 'LayerNormalization' as a built-in Keras object. Consider renaming <class 'keras_layer_normalization.layer_normalization.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x000001F0634C0DC0> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'keras_multi_head.multi_head_attention.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_layer_normalization.layer_normalization.LayerNormalization object at 0x000001F0634FA8B0> has the same name 'LayerNormalization' as a built-in Keras object. Consider renaming <class 'keras_layer_normalization.layer_normalization.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_layer_normalization.layer_normalization.LayerNormalization object at 0x000001F0634C7730> has the same name 'LayerNormalization' as a built-in Keras object. Consider renaming <class 'keras_layer_normalization.layer_normalization.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x000001F0634B8040> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'keras_multi_head.multi_head_attention.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_layer_normalization.layer_normalization.LayerNormalization object at 0x000001F063556490> has the same name 'LayerNormalization' as a built-in Keras object. Consider renaming <class 'keras_layer_normalization.layer_normalization.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_layer_normalization.layer_normalization.LayerNormalization object at 0x000001F0635E5880> has the same name 'LayerNormalization' as a built-in Keras object. Consider renaming <class 'keras_layer_normalization.layer_normalization.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x000001F0635ED6D0> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'keras_multi_head.multi_head_attention.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_layer_normalization.layer_normalization.LayerNormalization object at 0x000001F0631C9910> has the same name 'LayerNormalization' as a built-in Keras object. Consider renaming <class 'keras_layer_normalization.layer_normalization.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_layer_normalization.layer_normalization.LayerNormalization object at 0x000001F0631A8DF0> has the same name 'LayerNormalization' as a built-in Keras object. Consider renaming <class 'keras_layer_normalization.layer_normalization.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x000001F0631BBE80> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'keras_multi_head.multi_head_attention.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_layer_normalization.layer_normalization.LayerNormalization object at 0x000001F0635440A0> has the same name 'LayerNormalization' as a built-in Keras object. Consider renaming <class 'keras_layer_normalization.layer_normalization.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_layer_normalization.layer_normalization.LayerNormalization object at 0x000001F063104280> has the same name 'LayerNormalization' as a built-in Keras object. Consider renaming <class 'keras_layer_normalization.layer_normalization.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x000001F06319FE50> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'keras_multi_head.multi_head_attention.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_layer_normalization.layer_normalization.LayerNormalization object at 0x000001F0635FB700> has the same name 'LayerNormalization' as a built-in Keras object. Consider renaming <class 'keras_layer_normalization.layer_normalization.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_layer_normalization.layer_normalization.LayerNormalization object at 0x000001F06364CDC0> has the same name 'LayerNormalization' as a built-in Keras object. Consider renaming <class 'keras_layer_normalization.layer_normalization.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x000001F06504EE20> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'keras_multi_head.multi_head_attention.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_layer_normalization.layer_normalization.LayerNormalization object at 0x000001F0650540D0> has the same name 'LayerNormalization' as a built-in Keras object. Consider renaming <class 'keras_layer_normalization.layer_normalization.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_layer_normalization.layer_normalization.LayerNormalization object at 0x000001F0650D63A0> has the same name 'LayerNormalization' as a built-in Keras object. Consider renaming <class 'keras_layer_normalization.layer_normalization.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x000001F0634B8BE0> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'keras_multi_head.multi_head_attention.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_layer_normalization.layer_normalization.LayerNormalization object at 0x000001F0650ED850> has the same name 'LayerNormalization' as a built-in Keras object. Consider renaming <class 'keras_layer_normalization.layer_normalization.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras_layer_normalization.layer_normalization.LayerNormalization object at 0x000001F000005760> has the same name 'LayerNormalization' as a built-in Keras object. Consider renaming <class 'keras_layer_normalization.layer_normalization.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "filename = 'model_test.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor=ktrain.get_predictor(learner.model,preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labels']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = \"fuck trump covid\"\n",
    "predictor.predict([example])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Critical'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prediction(data):\n",
    "    if predictor.predict([data])==['labels']:\n",
    "        return 'Critical'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "prediction(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @HAGnews2: 😱Toxicity of #mRNA vaccines has been consensus since the beginning of their development - the only way to approve them is '#e…\n",
      "Prediction: Neutral\n",
      "Students of history should have foreseen Russia’s invasion of Ukraine. Let’s hope someone will figure out the next post-COVID struggle! #covid #covid-19 #war #thestrategybridge https://t.co/0pjWSLTkl2\n",
      "Prediction: Critical\n",
      "RT @BMJOpenSEM: New editorial on the observed decreased sports #participation during the #COVID-19 pandemic\n",
      "\n",
      "How should we react in a futur…\n",
      "Prediction: Neutral\n",
      "👏\n",
      "\n",
      "I hope this man has something up his sleeve\n",
      "\n",
      "Because talk needs to turn to action pretty soon\n",
      "\n",
      "#COVID19 #COVID #China #CCP #CCPVirus #vaccines #Russia #Ukraine https://t.co/6pGYl0dRuX\n",
      "Prediction: Critical\n",
      "Total Covid Death Distribution by County  For OH   2022-03-04:  Latest Covid Insights by Our Analytics Team using USAFacts #datavisualization #datascience #analytics #healthtech #data #covid19 #publichealth #covid #globalhealth #RStats https://t.co/6zztRZmGQ5\n",
      "Prediction: Neutral\n",
      "How Will #Housing Marking in College Towns Fare Post #COVID? https://t.co/cDVPEnhqjU\n",
      "Prediction: Neutral\n",
      "#Justice4Lavanya\n",
      "#Justice4Harsha\n",
      "#HijabRow\n",
      "#NawabMalik\n",
      "#Covid\n",
      "\n",
      "Few issues which lost magnitude due to #RussianUkrainianWar\n",
      "Prediction: Neutral\n",
      "RT @njoyflyfishing: Total Covid Death Distribution by County  For OH   2022-03-04:  Latest Covid Insights by Our Analytics Team using USAFa…\n",
      "Prediction: Neutral\n",
      "@P_Charles_ID_Dr Is there a role for a #clinicaltrial of temporary/short-term cardioprotective interventions post-#COVID? 3 months of statin? B-blocker? Aspirin? etc? @SverdlovAaron\n",
      "Prediction: Neutral\n",
      "#COVID  #COVID19   #COVID_19  #Omicron  The evidence has been with us all along, and finally someone has put it together. https://t.co/q5hToMApvR\n",
      "Prediction: Critical\n",
      "Now that #RussianUkrainianWar has overtaken #COVID, it would be great to hear @DrHilaryJones advice on war the way he advised on COVID .....\n",
      "\n",
      "#GMB \n",
      "#GBNews \n",
      "#BBCBreakfast https://t.co/wgY9WYO6mt\n",
      "Prediction: Critical\n",
      "RT @TheKoreaHerald: S. Korea’s daily COVID-19 cases continue to stay above 200,000\n",
      "#SouthKorea #COVID #omicron\n",
      "https://t.co/R0N4vFF8yw\n",
      "Prediction: Neutral\n",
      "RT @ltgrusselhonore: No public tours last time I spoke w them they short officers/#COVID rules .There would be a officer 👮‍♀️ problem if th…\n",
      "Prediction: Critical\n",
      "Total Covid Death Distribution by County  For OH   2022-03-04:  Latest Covid Insights by Our Analytics Team using USAFacts #datavisualization #datascience #analytics #healthtech #data #covid19 #publichealth #covid #globalhealth #RStats https://t.co/4XrPRltxhE\n",
      "Prediction: Neutral\n",
      "RT @EricWishart: Because of #COVID, the mask shop is closed.\n",
      "#HongKong #China https://t.co/FYcJX1pzNK\n",
      "Prediction: Critical\n",
      "RT @Yale: Nasal approach to #COVID vaccination gains traction \n",
      "\n",
      "@YaleMed @VirusesImmunity \n",
      "https://t.co/5sQnPQyji9\n",
      "Prediction: Neutral\n",
      "#COVID  #Omicron #COVID19   #COVID_19   Many Americans contracted a strange disease in 19 years. This report confirmed that it was COVID-19 and Fort Detrick was the place of origin. . https://t.co/QoRQXvX4tx\n",
      "Prediction: Neutral\n",
      "#COVID  #Omicron #COVID19   #COVID_19    This report is so comprehensive, I should show it to my friends! https://t.co/q5hToMApvR\n",
      "Prediction: Critical\n",
      "RT @RealityUK_2016: #BorisJohnson accused of 'risking national security' with peerage for #Russian-born crony \n",
      "The #PrimeMinister made #Evg…\n",
      "Prediction: Critical\n",
      "RT @NFIDvaccines: Testing is an important tool to help #StopTheSpread of #COVID-19 &amp; help get back to daily activities safely. \n",
      "\n",
      "Tests can…\n",
      "Prediction: Neutral\n"
     ]
    }
   ],
   "source": [
    "testing_data = pd.read_excel('tweets_semi_labeled.xlsx')['full_text'][200:300]\n",
    "for tweet in testing_data[:20]:\n",
    "    print(tweet)\n",
    "    print(f\"Prediction: {prediction(tweet)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, transformer_layer_call_fn, transformer_layer_call_and_return_conditional_losses, add_layer_call_fn while saving (showing 5 of 166). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "saved_model = pickle.dumps(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ram://538c6b40-aedc-4d76-a2c9-b7edcec049b8/variables/variables\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\risto\\OneDrive\\Asiakirjat\\masters\\SNLP\\project\\newtry.ipynb Cell 15'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/risto/OneDrive/Asiakirjat/masters/SNLP/project/newtry.ipynb#ch0000015?line=0'>1</a>\u001b[0m knn_from_pickle \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mloads(saved_model)\n",
      "File \u001b[1;32mc:\\Users\\risto\\OneDrive\\Asiakirjat\\masters\\SNLP\\project\\venv\\lib\\site-packages\\keras\\saving\\pickle_utils.py:48\u001b[0m, in \u001b[0;36mdeserialize_model_from_bytecode\u001b[1;34m(serialized_model)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/risto/OneDrive/Asiakirjat/masters/SNLP/project/venv/lib/site-packages/keras/saving/pickle_utils.py?line=45'>46</a>\u001b[0m       \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mGFile(dest_path, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m     <a href='file:///c%3A/Users/risto/OneDrive/Asiakirjat/masters/SNLP/project/venv/lib/site-packages/keras/saving/pickle_utils.py?line=46'>47</a>\u001b[0m         f\u001b[39m.\u001b[39mwrite(archive\u001b[39m.\u001b[39mextractfile(name)\u001b[39m.\u001b[39mread())\n\u001b[1;32m---> <a href='file:///c%3A/Users/risto/OneDrive/Asiakirjat/masters/SNLP/project/venv/lib/site-packages/keras/saving/pickle_utils.py?line=47'>48</a>\u001b[0m model \u001b[39m=\u001b[39m save_module\u001b[39m.\u001b[39;49mload_model(temp_dir)\n\u001b[0;32m     <a href='file:///c%3A/Users/risto/OneDrive/Asiakirjat/masters/SNLP/project/venv/lib/site-packages/keras/saving/pickle_utils.py?line=48'>49</a>\u001b[0m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mrmtree(temp_dir)\n\u001b[0;32m     <a href='file:///c%3A/Users/risto/OneDrive/Asiakirjat/masters/SNLP/project/venv/lib/site-packages/keras/saving/pickle_utils.py?line=49'>50</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\risto\\OneDrive\\Asiakirjat\\masters\\SNLP\\project\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/risto/OneDrive/Asiakirjat/masters/SNLP/project/venv/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/risto/OneDrive/Asiakirjat/masters/SNLP/project/venv/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> <a href='file:///c%3A/Users/risto/OneDrive/Asiakirjat/masters/SNLP/project/venv/lib/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/risto/OneDrive/Asiakirjat/masters/SNLP/project/venv/lib/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/risto/OneDrive/Asiakirjat/masters/SNLP/project/venv/lib/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\risto\\OneDrive\\Asiakirjat\\masters\\SNLP\\project\\venv\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:977\u001b[0m, in \u001b[0;36mload_internal\u001b[1;34m(export_dir, tags, options, loader_cls, filters)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/risto/OneDrive/Asiakirjat/masters/SNLP/project/venv/lib/site-packages/tensorflow/python/saved_model/load.py?line=973'>974</a>\u001b[0m   loader \u001b[39m=\u001b[39m loader_cls(object_graph_proto, saved_model_proto, export_dir,\n\u001b[0;32m    <a href='file:///c%3A/Users/risto/OneDrive/Asiakirjat/masters/SNLP/project/venv/lib/site-packages/tensorflow/python/saved_model/load.py?line=974'>975</a>\u001b[0m                       ckpt_options, options, filters)\n\u001b[0;32m    <a href='file:///c%3A/Users/risto/OneDrive/Asiakirjat/masters/SNLP/project/venv/lib/site-packages/tensorflow/python/saved_model/load.py?line=975'>976</a>\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mNotFoundError \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> <a href='file:///c%3A/Users/risto/OneDrive/Asiakirjat/masters/SNLP/project/venv/lib/site-packages/tensorflow/python/saved_model/load.py?line=976'>977</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/risto/OneDrive/Asiakirjat/masters/SNLP/project/venv/lib/site-packages/tensorflow/python/saved_model/load.py?line=977'>978</a>\u001b[0m       \u001b[39mstr\u001b[39m(err) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m You may be trying to load on a different device \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/risto/OneDrive/Asiakirjat/masters/SNLP/project/venv/lib/site-packages/tensorflow/python/saved_model/load.py?line=978'>979</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mfrom the computational device. Consider setting the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/risto/OneDrive/Asiakirjat/masters/SNLP/project/venv/lib/site-packages/tensorflow/python/saved_model/load.py?line=979'>980</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39m`experimental_io_device` option in `tf.saved_model.LoadOptions` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/risto/OneDrive/Asiakirjat/masters/SNLP/project/venv/lib/site-packages/tensorflow/python/saved_model/load.py?line=980'>981</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mto the io_device such as \u001b[39m\u001b[39m'\u001b[39m\u001b[39m/job:localhost\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/risto/OneDrive/Asiakirjat/masters/SNLP/project/venv/lib/site-packages/tensorflow/python/saved_model/load.py?line=981'>982</a>\u001b[0m root \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39mget(\u001b[39m0\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/risto/OneDrive/Asiakirjat/masters/SNLP/project/venv/lib/site-packages/tensorflow/python/saved_model/load.py?line=982'>983</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(loader, Loader):\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ram://538c6b40-aedc-4d76-a2c9-b7edcec049b8/variables/variables\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'."
     ]
    }
   ],
   "source": [
    "knn_from_pickle = pickle.loads(saved_model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1699b388bd678768f544dd6534e58979417dc4074b6b5ce767e74c5ad0a1cf40"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
