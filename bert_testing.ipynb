{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sources:\n",
    "https://colab.research.google.com/github/digitalepidemiologylab/covid-twitter-bert/blob/master/CT_BERT_Huggingface_(GPU_training).ipynb#scrollTo=11kI0lhIJoxd\n",
    "https://towardsdatascience.com/sentiment-analysis-in-10-minutes-with-bert-and-hugging-face-294e8a04b671"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import InputExample, InputFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 570/570 [00:00<00:00, 63.0kB/s]\n",
      "Downloading: 100%|██████████| 511M/511M [00:31<00:00, 17.2MB/s] \n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Downloading: 100%|██████████| 226k/226k [00:01<00:00, 142kB/s]  \n",
      "Downloading: 100%|██████████| 28.0/28.0 [00:00<00:00, 3.47kB/s]\n"
     ]
    }
   ],
   "source": [
    "# model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# odel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'digitalepidemiologylab/covid-twitter-bert' # CT-BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "   AutoConfig,\n",
    "   AutoTokenizer,\n",
    "   TFAutoModelForSequenceClassification,\n",
    "   AdamW,\n",
    "   glue_convert_examples_to_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1.47G/1.47G [01:11<00:00, 20.5MB/s] \n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small function only used for formatting the output\n",
    "def format_prediction(preds, label_mapping, label_name):\n",
    "    preds = tf.nn.softmax(preds, axis=1)\n",
    "    formatted_preds = []\n",
    "    for pred in preds.numpy():\n",
    "        # convert to Python types and sort\n",
    "        pred = {label: float(probability) for label, probability in zip(label_mapping.values(), pred)}\n",
    "        pred = {k: v for k, v in sorted(pred.items(), key=lambda item: item[1], reverse=True)}\n",
    "        formatted_preds.append({label_name: list(pred.keys())[0], f'{label_name}_probabilities': pred})\n",
    "    return formatted_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import pandas as pd\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('tweets_semi_labeled.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = data['full_text'][:200]\n",
    "labels = data['Label (critical: 1/neutral: 0)'][:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'tweets': tweets, 'labels': labels})\n",
    "# print(good_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {'critical': 1, 'neutral': 0}\n",
    "# train_size = 150\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf_data = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (tf.cast(df['tweets'].values, tf.string), tf.cast(df['labels'].values, tf.int64))\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_mapping = {\"0\": \"negative\", \"1\": \"positive\"} # only for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label Mapping:{\n",
      "    \"critical\": 1,\n",
      "    \"neutral\": 0\n",
      "}\n",
      "\n",
      "Logits: TFSequenceClassifierOutput(loss=None, logits=<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[ 0.17656091, -0.30736065]], dtype=float32)>, hidden_states=None, attentions=None)\n",
      "\n",
      "Probabilities:[\n",
      "    {\n",
      "        \"sentiment\": 1,\n",
      "        \"sentiment_probabilities\": {\n",
      "            \"1\": 0.6186734437942505,\n",
      "            \"0\": 0.3813265264034271\n",
      "        }\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "input_text = 'i love you'\n",
    "# Tokenize the input \n",
    "input_ids = tf.constant(tokenizer.encode(input_text, add_special_tokens=True))[None, :]\n",
    "# Run predictions\n",
    "preds = model(input_ids)\n",
    "# format logits\n",
    "formatted_preds = format_prediction(preds[0], label_mapping, 'sentiment')\n",
    "\n",
    "print(f'\\nLabel Mapping:{json.dumps(label_mapping, indent=4)}')\n",
    "print(f'\\nLogits: {preds}')\n",
    "print(f'\\nProbabilities:{json.dumps(formatted_preds, indent=4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1699b388bd678768f544dd6534e58979417dc4074b6b5ce767e74c5ad0a1cf40"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
